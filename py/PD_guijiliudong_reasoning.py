import json
import os
import time as time_module
from datetime import datetime

# å¯é€‰å¯¼å…¥ï¼Œé¿å…å¯¼å…¥é”™è¯¯
try:
    import requests
except ImportError:
    requests = None

try:
    import urllib3
except ImportError:
    urllib3 = None

class PD_guijiliudong_reasoning:
    """
    ç¡…åŸºæµåŠ¨æ¨ç†æ¨¡å‹èŠ‚ç‚¹
    ä¸“é—¨ç”¨äºæ”¯æŒæ·±åº¦æ€ç»´é“¾çš„æ¨ç†æ¨¡å‹ï¼ˆDeepSeek-R1ã€QwQç­‰ï¼‰
    """
    
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        # æ¨ç†æ¨¡å‹åˆ—è¡¨
        reasoning_models = [
            # DeepSeek-R1ç³»åˆ—ï¼ˆæœ€å¼ºæ¨ç†ï¼‰âœ… æ¨è
            "deepseek-ai/DeepSeek-R1",  # âœ… ç¨³å®šå¯ç”¨
            "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",  # âœ… ç¨³å®šå¯ç”¨
            "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",  # âœ… ç¨³å®šå¯ç”¨
            "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",  # âœ… ç¨³å®šå¯ç”¨ï¼Œé€Ÿåº¦å¿«
            
            # Qwenæ¨ç†ç³»åˆ—
            "Qwen/QwQ-32B",  # âœ… ç¨³å®šå¯ç”¨
        ]
        
        return {
            "required": {
                "system_prompt": ("STRING", {
                    "default": "ä½ æ˜¯ä¸€ä¸ªå¼ºå¤§çš„AIæ¨ç†åŠ©æ‰‹ï¼Œæ“…é•¿æ·±åº¦æ€è€ƒå’Œé€»è¾‘æ¨ç†ã€‚è¯·ä¸€æ­¥æ­¥åˆ†æé—®é¢˜ï¼Œå±•ç¤ºä½ çš„æ¨ç†è¿‡ç¨‹ã€‚",
                    "multiline": True
                }),
            },
            "optional": {
                "user_prompt": ("STRING", {
                    "default": "è¯·è§£é‡Šä¸€ä¸‹é‡å­çº ç¼ çš„åŸç†ã€‚",
                    "multiline": True
                }),
                "model": (reasoning_models, {"default": "deepseek-ai/DeepSeek-R1"}),
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "temperature": ("FLOAT", {"default": 0.6, "min": 0.0, "max": 2.0, "step": 0.1}),
                "max_tokens": ("INT", {"default": 4096, "min": 1, "max": 8192}),
                "retry_count": ("INT", {"default": 3, "min": 1, "max": 5}),
                "debug_mode": ("BOOLEAN", {"default": False}),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("reasoning", "output_text", "model_name", "info")
    FUNCTION = "generate_reasoning"
    CATEGORY = "PD_Nodes/Reasoning"
    
    def load_config(self):
        """ä»config.jsonåŠ è½½APIå¯†é’¥"""
        config_path = os.path.join(os.path.dirname(__file__), "config.json")
        
        if not os.path.exists(config_path):
            raise Exception("æ‰¾ä¸åˆ°config.jsoné…ç½®æ–‡ä»¶")
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                
            api_key = None
            if 'siliconflow_api_key' in config:
                api_key = config['siliconflow_api_key']
            elif 'api_key' in config:
                api_key = config['api_key']
            
            if not api_key or api_key.strip() == "":
                raise Exception("åœ¨config.jsonä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„APIå¯†é’¥")
                
            return api_key.strip()
            
        except Exception as e:
            raise Exception(f"è¯»å–config.jsonå¤±è´¥: {str(e)}")
    
    def calculate_cost(self, model, prompt_tokens, completion_tokens):
        """è®¡ç®—APIè°ƒç”¨è´¹ç”¨ï¼ˆäººæ°‘å¸ï¼‰"""
        # ç¡…åŸºæµåŠ¨ä»·æ ¼è¡¨ï¼ˆå…ƒ/ç™¾ä¸‡tokensï¼‰
        pricing = {
            "deepseek-ai/DeepSeek-R1": {"input": 0.55, "output": 2.19},
            "Pro/deepseek-ai/DeepSeek-R1": {"input": 1.0, "output": 4.0},
            "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {"input": 0.14, "output": 0.28},
            "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {"input": 0.07, "output": 0.14},
            "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {"input": 0.035, "output": 0.07},
            "Qwen/QwQ-32B": {"input": 0.135, "output": 0.135},
            "Qwen/Qwen3-30B-A3B-Thinking-2507": {"input": 0.1, "output": 0.1},
        }
        
        # è·å–ä»·æ ¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤ä»·æ ¼
        price = pricing.get(model, {"input": 0.1, "output": 0.1})
        
        # è®¡ç®—è´¹ç”¨ï¼ˆå…ƒï¼‰
        input_cost = (prompt_tokens / 1000000) * price["input"]
        output_cost = (completion_tokens / 1000000) * price["output"]
        total_cost = input_cost + output_cost
        
        return {
            "input_cost": input_cost,
            "output_cost": output_cost,
            "total_cost": total_cost
        }
    
    def call_api(self, api_key, model, messages, temperature, max_tokens, retry_count=3):
        """è°ƒç”¨ç¡…åŸºæµåŠ¨APIï¼ˆæ”¯æŒé‡è¯•ï¼‰"""
        url = "https://api.siliconflow.cn/v1/chat/completions"
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": False
        }
        
        if not requests:
            raise Exception("requestsåº“æœªå®‰è£…")
        
        # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®è¶…æ—¶æ—¶é—´
        timeout = 300  # é»˜è®¤5åˆ†é’Ÿ
        if "235B" in model or "80B" in model:
            timeout = 600  # å¤§æ¨¡å‹10åˆ†é’Ÿ
        
        # é‡è¯•æœºåˆ¶
        last_error = None
        for attempt in range(retry_count):
            try:
                if attempt > 0:
                    wait_time = attempt * 2  # é€’å¢ç­‰å¾…æ—¶é—´
                    print(f"â³ ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {wait_time} ç§’...")
                    time_module.sleep(wait_time)
                
                response = requests.post(url, headers=headers, json=payload, timeout=timeout)
                
                if response.status_code == 200:
                    return response.json()
                
                # å¤„ç†é200çŠ¶æ€ç 
                error_msg = f"HTTP {response.status_code}"
                error_detail = ""
                try:
                    error_json = response.json()
                    error_detail = error_json.get("error", {}).get("message", "")
                    if not error_detail:
                        error_detail = str(error_json.get("error", ""))
                    if error_detail:
                        error_msg += f": {error_detail}"
                except:
                    error_msg += f": {response.text[:200]}"
                
                # æŸäº›é”™è¯¯ä¸éœ€è¦é‡è¯•
                if response.status_code in [400, 401, 403, 404]:
                    raise Exception(f"{error_msg}\nğŸ’¡ æç¤º: æ­¤æ¨¡å‹å¯èƒ½ä¸å¯ç”¨æˆ–éœ€è¦ç‰¹æ®Šæƒé™")
                
                last_error = Exception(error_msg)
                
            except requests.exceptions.Timeout as e:
                last_error = Exception(f"è¯·æ±‚è¶…æ—¶ï¼ˆ>{timeout}ç§’ï¼‰\nğŸ’¡ æç¤º: æ¨¡å‹å“åº”è¾ƒæ…¢ï¼Œå»ºè®®ç¨åé‡è¯•æˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹")
            except requests.exceptions.ConnectionError as e:
                last_error = Exception(f"ç½‘ç»œè¿æ¥å¤±è´¥: {str(e)}\nğŸ’¡ æç¤º: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä»£ç†è®¾ç½®")
            except requests.exceptions.RequestException as e:
                last_error = Exception(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")
            except Exception as e:
                if "timeout" in str(e).lower():
                    last_error = Exception(f"è¯·æ±‚è¶…æ—¶: {str(e)}\nğŸ’¡ æç¤º: ç½‘ç»œä¸ç¨³å®šæˆ–æ¨¡å‹è´Ÿè½½è¿‡é«˜")
                else:
                    last_error = e
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        if last_error:
            raise last_error
        
        raise Exception("APIè°ƒç”¨å¤±è´¥ï¼ŒæœªçŸ¥é”™è¯¯")
    
    def generate_reasoning(self, system_prompt, user_prompt="", model="", api_key="", temperature=0.6, max_tokens=4096, retry_count=3, debug_mode=False):
        """ç”Ÿæˆæ¨ç†å†…å®¹"""
        
        start_time = time_module.time()
        
        try:
            # éªŒè¯è¾“å…¥
            if not user_prompt or not user_prompt.strip():
                raise Exception("user_promptä¸èƒ½ä¸ºç©º")
            
            # è®¾ç½®é»˜è®¤æ¨¡å‹
            if not model or model.strip() == "":
                model = "deepseek-ai/DeepSeek-R1"
            
            # è·å–APIå¯†é’¥
            if not api_key or api_key.strip() == "":
                api_key = self.load_config()
            else:
                api_key = api_key.strip()
            
            # æ„å»ºæ¶ˆæ¯
            messages = []
            if system_prompt and system_prompt.strip():
                messages.append({"role": "system", "content": system_prompt.strip()})
            messages.append({"role": "user", "content": user_prompt.strip()})
            
            # æ¨¡å‹æç¤º
            model_tips = {
                "Pro/": "âš ï¸  æ­¤æ¨¡å‹éœ€è¦Proæƒé™",
                "80B": "âš ï¸  å¤§æ¨¡å‹ï¼Œå“åº”è¾ƒæ…¢ï¼ˆè¶…æ—¶10åˆ†é’Ÿï¼‰",
                "235B": "âš ï¸  è¶…å¤§æ¨¡å‹ï¼Œå“åº”å¾ˆæ…¢ï¼ˆè¶…æ—¶10åˆ†é’Ÿï¼‰",
            }
            for key, tip in model_tips.items():
                if key in model:
                    print(tip)
                    break
            
            # è°ƒç”¨API
            print(f"ğŸ§  è°ƒç”¨æ¨ç†æ¨¡å‹: {model}")
            print(f"ğŸ”„ é‡è¯•æ¬¡æ•°: æœ€å¤š {retry_count} æ¬¡")
            print(f"â³ ç­‰å¾…å“åº”ä¸­...")
            response = self.call_api(api_key, model, messages, temperature, max_tokens, retry_count)
            
            # è®¡ç®—è€—æ—¶
            elapsed_time = time_module.time() - start_time
            print(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            
            # æ‰“å°åŸå§‹å“åº”ç»“æ„ç”¨äºè°ƒè¯•
            if debug_mode:
                print(f"\n{'='*50}")
                print(f"ğŸ” è°ƒè¯•æ¨¡å¼ - APIå®Œæ•´å“åº”:")
                print(f"{'='*50}")
                print(json.dumps(response, indent=2, ensure_ascii=False))
                print(f"{'='*50}\n")
            
            print(f"ğŸ“¦ APIå“åº”ç»“æ„: {list(response.keys())}")
            
            # æå–ç»“æœ
            if "choices" in response and len(response["choices"]) > 0:
                choice = response["choices"][0]
                message = choice["message"]
                
                print(f"ğŸ“ Messageå­—æ®µ: {list(message.keys())}")
                
                # å°è¯•å¤šç§å¯èƒ½çš„æ€ç»´é“¾å­—æ®µå
                reasoning_chain = ""
                possible_fields = ["reasoning_content", "reasoning", "thinking", "thought_process"]
                for field in possible_fields:
                    if field in message and message[field]:
                        reasoning_chain = message[field]
                        print(f"âœ… æ‰¾åˆ°æ€ç»´é“¾å­—æ®µ: {field}")
                        break
                
                generated_text = message.get("content", "")
                
                # æ‰“å°æ€ç»´é“¾ä¿¡æ¯
                if reasoning_chain:
                    reasoning_len = len(reasoning_chain)
                    print(f"ğŸ§  æ€ç»´é“¾é•¿åº¦: {reasoning_len:,} å­—ç¬¦")
                    print(f"ğŸ§  æ€ç»´é“¾å‰200å­—ç¬¦é¢„è§ˆ:\n{reasoning_chain[:200]}...")
                else:
                    print(f"âš ï¸  æœªæ‰¾åˆ°æ€ç»´é“¾å†…å®¹ï¼Œå¯èƒ½çš„åŸå› ï¼š")
                    print(f"   1. æ¨¡å‹ä¸æ”¯æŒæ€ç»´é“¾è¾“å‡º")
                    print(f"   2. APIå­—æ®µåä¸åŒ¹é…")
                    print(f"   3. æ€ç»´é“¾å†…å®¹ä¸ºç©º")
                
                # æ„å»ºinfoä¿¡æ¯
                info_lines = []
                info_lines.append(f"{'='*40}")
                info_lines.append(f"ğŸ¤– æ¨ç†æ¨¡å‹è°ƒç”¨ä¿¡æ¯")
                info_lines.append(f"{'='*40}")
                info_lines.append(f"")
                info_lines.append(f"ğŸ“‹ æ¨¡å‹: {model}")
                info_lines.append(f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                info_lines.append(f"â±ï¸  è€—æ—¶: {elapsed_time:.2f} ç§’")
                info_lines.append(f"")
                
                # æ€ç»´é“¾çŠ¶æ€ï¼ˆè¯¦ç»†ä¿¡æ¯ï¼‰
                if reasoning_chain:
                    reasoning_len = len(reasoning_chain)
                    reasoning_lines = reasoning_chain.count('\n') + 1
                    info_lines.append(f"ğŸ§  æ€ç»´é“¾: âœ… å·²ç”Ÿæˆ")
                    info_lines.append(f"   â€¢ å­—ç¬¦æ•°: {reasoning_len:,}")
                    info_lines.append(f"   â€¢ è¡Œæ•°: {reasoning_lines:,}")
                    # æŸ¥æ‰¾æ€ç»´é“¾å­—æ®µå
                    found_field = ""
                    for field in ["reasoning_content", "reasoning", "thinking", "thought_process"]:
                        if field in message and message[field]:
                            found_field = field
                            break
                    if found_field:
                        info_lines.append(f"   â€¢ å­—æ®µå: {found_field}")
                else:
                    info_lines.append(f"ğŸ§  æ€ç»´é“¾: âŒ æœªç”Ÿæˆ")
                    info_lines.append(f"   â€¢ å¯èƒ½åŸå› : APIä¸è¿”å›è¯¥å­—æ®µ")
                    info_lines.append(f"   â€¢ å»ºè®®: å¼€å¯debug_modeæŸ¥çœ‹å®Œæ•´å“åº”")
                info_lines.append(f"")
                
                # Tokenç»Ÿè®¡å’Œè´¹ç”¨
                if "usage" in response:
                    usage = response["usage"]
                    prompt_tokens = usage.get('prompt_tokens', 0)
                    completion_tokens = usage.get('completion_tokens', 0)
                    total_tokens = usage.get('total_tokens', 0)
                    
                    info_lines.append(f"ğŸ“Š Tokenä½¿ç”¨:")
                    info_lines.append(f"   â€¢ è¾“å…¥: {prompt_tokens:,} tokens")
                    info_lines.append(f"   â€¢ è¾“å‡º: {completion_tokens:,} tokens")
                    info_lines.append(f"   â€¢ æ€»è®¡: {total_tokens:,} tokens")
                    info_lines.append(f"")
                    
                    # è®¡ç®—è´¹ç”¨
                    cost = self.calculate_cost(model, prompt_tokens, completion_tokens)
                    info_lines.append(f"ğŸ’° è´¹ç”¨ä¼°ç®—:")
                    info_lines.append(f"   â€¢ è¾“å…¥: Â¥{cost['input_cost']:.6f}")
                    info_lines.append(f"   â€¢ è¾“å‡º: Â¥{cost['output_cost']:.6f}")
                    info_lines.append(f"   â€¢ æ€»è®¡: Â¥{cost['total_cost']:.6f}")
                    info_lines.append(f"")
                
                # è¾“å‡ºç»Ÿè®¡
                output_len = len(generated_text)
                info_lines.append(f"ğŸ“ è¾“å‡ºé•¿åº¦: {output_len:,} å­—ç¬¦")
                info_lines.append(f"âœ… çŠ¶æ€: {choice.get('finish_reason', 'unknown')}")
                info_lines.append(f"")
                
                # æ·»åŠ ä½¿ç”¨æç¤º
                if reasoning_chain:
                    info_lines.append(f"ğŸ’¡ æç¤º:")
                    info_lines.append(f"   â€¢ reasoning è¾“å‡ºåŒ…å«å®Œæ•´çš„æ€ç»´é“¾")
                    info_lines.append(f"   â€¢ å¯è¿æ¥åˆ°æ–‡æœ¬æ˜¾ç¤ºèŠ‚ç‚¹æŸ¥çœ‹è¯¦ç»†æ¨ç†è¿‡ç¨‹")
                    info_lines.append(f"   â€¢ output_text åŒ…å«æœ€ç»ˆç­”æ¡ˆ")
                else:
                    info_lines.append(f"ğŸ’¡ æç¤º:")
                    info_lines.append(f"   â€¢ å¼€å¯ debug_mode å¯æŸ¥çœ‹å®Œæ•´APIå“åº”")
                    info_lines.append(f"   â€¢ æŸäº›æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå•ç‹¬çš„æ€ç»´é“¾è¾“å‡º")
                    info_lines.append(f"   â€¢ æ€ç»´é“¾å¯èƒ½åŒ…å«åœ¨ output_text ä¸­")
                
                info_lines.append(f"{'='*40}")
                
                info_text = "\n".join(info_lines)
                
                # æœ€ç»ˆæ‰“å°æ€»ç»“
                print(f"\nğŸ‰ æ¨ç†å®Œæˆ!")
                print(f"   â€¢ æ€ç»´é“¾: {'âœ… ' + str(len(reasoning_chain)) + ' å­—ç¬¦' if reasoning_chain else 'âŒ æœªç”Ÿæˆ'}")
                print(f"   â€¢ è¾“å‡ºæ–‡æœ¬: {len(generated_text)} å­—ç¬¦")
                print(f"   â€¢ æ€»è€—æ—¶: {elapsed_time:.2f}ç§’\n")
                
                return (reasoning_chain, generated_text, model, info_text)
            else:
                error_msg = "APIè¿”å›æ ¼å¼å¼‚å¸¸"
                error_info = f"âŒ é”™è¯¯\nğŸ“‹ æ¨¡å‹: {model}\nğŸš« {error_msg}"
                return ("", error_msg, model, error_info)
                
        except Exception as e:
            elapsed_time = time_module.time() - start_time
            error_msg = f"æ¨ç†è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}"
            
            # æ„å»ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_info_lines = []
            error_info_lines.append(f"{'='*40}")
            error_info_lines.append(f"âŒ è°ƒç”¨å¤±è´¥")
            error_info_lines.append(f"{'='*40}")
            error_info_lines.append(f"")
            error_info_lines.append(f"ğŸ“‹ æ¨¡å‹: {model}")
            error_info_lines.append(f"â±ï¸  è€—æ—¶: {elapsed_time:.2f}ç§’")
            error_info_lines.append(f"")
            error_info_lines.append(f"ğŸš« é”™è¯¯ä¿¡æ¯:")
            error_info_lines.append(f"{str(e)}")
            error_info_lines.append(f"")
            
            # æ ¹æ®é”™è¯¯ç±»å‹æä¾›å»ºè®®
            error_str = str(e).lower()
            if "timeout" in error_str or "è¶…æ—¶" in error_str:
                error_info_lines.append(f"ğŸ’¡ è§£å†³å»ºè®®:")
                error_info_lines.append(f"   1. å¢åŠ  retry_countï¼ˆå½“å‰: {retry_count}ï¼‰")
                error_info_lines.append(f"   2. é€‰æ‹©æ›´å°æ›´å¿«çš„æ¨¡å‹:")
                error_info_lines.append(f"      â€¢ deepseek-ai/DeepSeek-R1-Distill-Qwen-7B")
                error_info_lines.append(f"      â€¢ Qwen/QwQ-32B")
                error_info_lines.append(f"   3. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
                error_info_lines.append(f"   4. ç¨åé‡è¯•ï¼ˆå¯èƒ½æ˜¯æœåŠ¡å™¨è´Ÿè½½è¿‡é«˜ï¼‰")
            elif "403" in error_str or "401" in error_str or "æƒé™" in error_str:
                error_info_lines.append(f"ğŸ’¡ è§£å†³å»ºè®®:")
                error_info_lines.append(f"   1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
                error_info_lines.append(f"   2. æ­¤æ¨¡å‹å¯èƒ½éœ€è¦Proæƒé™")
                error_info_lines.append(f"   3. å°è¯•ä½¿ç”¨æ ‡å‡†æ¨¡å‹:")
                error_info_lines.append(f"      â€¢ deepseek-ai/DeepSeek-R1")
                error_info_lines.append(f"      â€¢ deepseek-ai/DeepSeek-R1-Distill-Qwen-7B")
            elif "404" in error_str or "ä¸å¯ç”¨" in error_str:
                error_info_lines.append(f"ğŸ’¡ è§£å†³å»ºè®®:")
                error_info_lines.append(f"   1. æ­¤æ¨¡å‹å¯èƒ½å·²ä¸‹çº¿æˆ–ä¸å­˜åœ¨")
                error_info_lines.append(f"   2. æ¨èä½¿ç”¨ä»¥ä¸‹ç¨³å®šæ¨¡å‹:")
                error_info_lines.append(f"      âœ… deepseek-ai/DeepSeek-R1")
                error_info_lines.append(f"      âœ… deepseek-ai/DeepSeek-R1-Distill-Qwen-32B")
                error_info_lines.append(f"      âœ… deepseek-ai/DeepSeek-R1-Distill-Qwen-7B")
                error_info_lines.append(f"      âœ… Qwen/QwQ-32B")
                error_info_lines.append(f"   3. å¼€å¯ debug_mode æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
            elif "network" in error_str or "ç½‘ç»œ" in error_str or "connection" in error_str:
                error_info_lines.append(f"ğŸ’¡ è§£å†³å»ºè®®:")
                error_info_lines.append(f"   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
                error_info_lines.append(f"   2. æ£€æŸ¥ä»£ç†è®¾ç½®")
                error_info_lines.append(f"   3. å°è¯•ä½¿ç”¨å…¶ä»–ç½‘ç»œç¯å¢ƒ")
                error_info_lines.append(f"   4. å¢åŠ  retry_count å‚æ•°")
            else:
                error_info_lines.append(f"ğŸ’¡ è§£å†³å»ºè®®:")
                error_info_lines.append(f"   1. å¼€å¯ debug_mode æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
                error_info_lines.append(f"   2. æ£€æŸ¥APIå¯†é’¥é…ç½®")
                error_info_lines.append(f"   3. å°è¯•ä½¿ç”¨æ¨èçš„ç¨³å®šæ¨¡å‹")
                error_info_lines.append(f"   4. æŸ¥çœ‹æ§åˆ¶å°å®Œæ•´é”™è¯¯ä¿¡æ¯")
            
            error_info_lines.append(f"")
            error_info_lines.append(f"{'='*40}")
            
            error_info = "\n".join(error_info_lines)
            
            print(f"\nâŒ é”™è¯¯: {error_msg}")
            print(error_info)
            
            return ("", error_msg, model, error_info)


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "PD_guijiliudong_reasoning": PD_guijiliudong_reasoning
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "PD_guijiliudong_reasoning": "PD æ¨ç†æ¨¡å‹ (Reasoning)"
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']

